{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright 2020 Vraj Shah, Arun Kumar\n",
    "#\n",
    "#Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#you may not use this file except in compliance with the License.\n",
    "#You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#Unless required by applicable law or agreed to in writing, software\n",
    "#distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#See the License for the specific language governing permissions and\n",
    "#limitations under the License.\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "np.random.seed(512)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/bobotran/Desktop/Homework/cse234/ML-Data-Prep-Zoo/MLFeatureTypeInference/Downstream-Benchmark')\n",
    "# from Load_Predictions import *\n",
    "# from Featurize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bobotran/Desktop/Homework/cse234/temp/SortingHatLib/resources/old/RandForest.pkl'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sortinghat.pylib as pl\n",
    "pl.rf_Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    0: 'numeric',\n",
    "    1: 'categorical',\n",
    "    2: 'datetime',\n",
    "    3: 'sentence',\n",
    "    4: 'url',\n",
    "    5: 'embedded-number',\n",
    "    6: 'list',\n",
    "    7: 'not-generalizable',\n",
    "    8: 'context-specific'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985 4233\n",
      "1985\n",
      "1985\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv('../../Benchmark-Labeled-Data/data_test.csv')\n",
    "test_metadata = pd.read_csv('../../Benchmark-Labeled-Data/Metadata/meta_data.csv')\n",
    "\n",
    "print(len(testdf),len(test_metadata))\n",
    "test_merged = pd.merge(testdf,test_metadata,on='Record_id')\n",
    "print(len(test_merged))\n",
    "\n",
    "# print(test_merged)\n",
    "y_true = test_merged.y_act.values.tolist()\n",
    "# print(y_true)\n",
    "print(len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76727f80e98f4c588cb1fbcd1a4b3418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "y_pred = []\n",
    "prv_csv_name,csv_name = '',''\n",
    "exception_indices = []\n",
    "\n",
    "for index, row in tqdm(test_merged.iterrows(), total=len(test_merged)):\n",
    "    col = row['Attribute_name']\n",
    "    csv_name = '../RawCSVFiles/' + row['name']\n",
    "    \n",
    "    try:\n",
    "        dataDownstream = pd.read_csv(csv_name, usecols=[col], encoding='latin1', low_memory=False)\n",
    "#         continue\n",
    "    except ValueError:\n",
    "        y_pred.append('Object')\n",
    "        continue\n",
    "    dataFeaturized = pl.FeaturizeFile(dataDownstream)\n",
    "    dataFeaturized1 = pl.FeatureExtraction(dataFeaturized)\n",
    "    # dataFeaturized1 = dataFeaturized1.fillna(0) # Makes categorical accuracy worse\n",
    "    y_RF = pl.Load_RF(dataFeaturized1)\n",
    "    \n",
    "#     y_RF = sortinghat.get_sortinghat_types(dataDownstream)\n",
    "#     _, y_RF = sortinghat.get_feature_types_as_arff(dataDownstream)\n",
    "    \n",
    "    # dataFeaturized = FeaturizeFile(dataDownstream)\n",
    "    # dataFeaturized1 = ProcessStats(dataFeaturized)\n",
    "    # dataFeaturized2 = FeatureExtraction(dataFeaturized,dataFeaturized1,0)\n",
    "    # dataFeaturized2 = dataFeaturized2.fillna(0)\n",
    "    # y_RF = sortinghat.Load_RF(dataFeaturized2)\n",
    "    assert len(y_RF) == 1\n",
    "    y_pred.append(class_map[int(y_RF[0])])\n",
    "#     y_pred.append(y_RF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n"
     ]
    }
   ],
   "source": [
    "# y_pred_full = y_pred\n",
    "# y_pred = [x for x in y_pred_full if x != 'Object']\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: \n",
      "0.8886649874055416\n",
      "\tnumeric: 0.9657430730478589\n",
      "\tcategorical: 0.947103274559194\n",
      "\tdatetime: 0.9929471032745592\n",
      "\tsentence: 0.9869017632241813\n",
      "\turl: 0.9984886649874055\n",
      "\tembedded-number: 0.9843828715365239\n",
      "\tlist: 0.9909319899244332\n",
      "\tnot-generalizable: 0.9596977329974811\n",
      "\tcontext-specific: 0.9596977329974811\n",
      "[[699   4   0   0   0   0   0   1   3]\n",
      " [ 10 399   0   5   0   0   1  35   6]\n",
      " [  1   2 135   0   0   3   0   0   0]\n",
      " [  0   4   0  80   0   0   1   5   2]\n",
      " [  0   1   0   1  30   0   0   0   0]\n",
      " [  2   5   1   0   0  75   0   1   1]\n",
      " [  1   3   0   3   0   4  41   0   5]\n",
      " [  6  14   6   3   1   0   0 181   2]\n",
      " [ 40  14   1   2   0   0   0   4 124]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          numeric      0.921     0.989     0.954       707\n",
      "      categorical      0.895     0.873     0.884       457\n",
      "         datetime      0.944     0.957     0.951       141\n",
      "         sentence      0.851     0.870     0.860        92\n",
      "              url      0.968     0.938     0.952        32\n",
      "  embedded-number      0.915     0.758     0.829        99\n",
      "             list      0.953     0.719     0.820        57\n",
      "not-generalizable      0.797     0.842     0.819       215\n",
      " context-specific      0.867     0.670     0.756       185\n",
      "\n",
      "        micro avg      0.896     0.889     0.892      1985\n",
      "        macro avg      0.901     0.846     0.869      1985\n",
      "     weighted avg      0.896     0.889     0.890      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "print('Accuracies: ')\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "for v in class_map.values():\n",
    "    one_vs_all_acc = accuracy_score(np.array(y_true) == v, np.array(y_pred) == v)\n",
    "    print('\\t{}: {}'.format(v, one_vs_all_acc))\n",
    "matrix = confusion_matrix(y_true, y_pred, labels=list(class_map.values()))\n",
    "print(matrix)\n",
    "print(classification_report(y_true, y_pred, labels=list(class_map.values()), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
